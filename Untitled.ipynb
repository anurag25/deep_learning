{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anurag/Desktop\n",
      "/home/anurag/Downloads/Deep Learning/PA1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print os.getcwd()\n",
    "os.chdir(\"/home/anurag/Downloads/Deep Learning/PA1\")\n",
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import train\n",
    "\n",
    "\n",
    "def load_mnist():\n",
    "    data_dir = '../data'\n",
    "\n",
    "    fd = open(os.path.join(data_dir, 'train-images.idx3-ubyte'))\n",
    "    loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "    trX = loaded[16:].reshape((60000, 28, 28, 1)).astype(np.float)\n",
    "\n",
    "    fd = open(os.path.join(data_dir, 'train-labels.idx1-ubyte'))\n",
    "    loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "    trY = loaded[8:].reshape((60000)).astype(np.int)\n",
    "\n",
    "    fd = open(os.path.join(data_dir, 't10k-images.idx3-ubyte'))\n",
    "    loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "    teX = loaded[16:].reshape((10000, 28, 28, 1)).astype(np.float)\n",
    "\n",
    "    fd = open(os.path.join(data_dir, 't10k-labels.idx1-ubyte'))\n",
    "    loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "    teY = loaded[8:].reshape((10000)).astype(np.int)\n",
    "\n",
    "    trY = np.asarray(trY)\n",
    "    teY = np.asarray(teY)\n",
    "\n",
    "    perm = np.random.permutation(trY.shape[0])\n",
    "    trX = trX[perm]\n",
    "    trY = trY[perm]\n",
    "\n",
    "    perm = np.random.permutation(teY.shape[0])\n",
    "    teX = teX[perm]\n",
    "    teY = teY[perm]\n",
    "\n",
    "    return trX, trY, teX, teY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 60000, columns: 28, third 28\n",
      "Rows: 10000, columns: 28, third 28\n"
     ]
    }
   ],
   "source": [
    "print('Rows: %d, columns: %d, third %d' % (trainX.shape[0], trainX.shape[1], trainX.shape[2]))\n",
    "print('Rows: %d, columns: %d, third %d' % (testX.shape[0], testX.shape[1], testX.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcfa54ce790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True,)\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    img = trainX[trainY == i][0].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/mnist_all.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcfa54cee50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=5, sharex=True, sharey=True,)\n",
    "ax = ax.flatten()\n",
    "for i in range(25):\n",
    "    img = trainX[trainY == 7][i].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/mnist_7.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_digit(digit_pixels, label='?'):\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            if digit_pixels[i, j] > 128:\n",
    "                print '#',\n",
    "            else:\n",
    "                print '.',\n",
    "        print ''\n",
    "\n",
    "    print 'Label: ', label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . # # # # # . . . . . . . . . . . . \n",
      ". . . . . . . # # # # # # # # # # # . . . . . . . . . . \n",
      ". . . . . . . # # # # # # # . # # # # . . . . . . . . . \n",
      ". . . . . . . . # # # . . . . . # # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . # # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . # # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . # # # . . . . . . . . . . \n",
      ". . . . . . . . . . . . . # # # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . . # # # # . . . . . . . . . . . . \n",
      ". . . . . . . . . . . # # # . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . # # # . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . # # # . . . . . . . . . # . . . . . . \n",
      ". . . . . . . . . # # # . . . . . # # # # # # . . . . . \n",
      ". . . . . . . . . # # # # # # # # # # # # # . . . . . . \n",
      ". . . . . . . . . # # # # # # # # # # # . . . . . . . . \n",
      ". . . . . . . . . . . # # # # # . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Label:  2\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . # # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . # # # # . . # # . . . . . . . \n",
      ". . . . . . . . . . . . # # # # # # # # # # . . . . . . \n",
      ". . . . . . . . . . . # # # # # . . # # # # . . . . . . \n",
      ". . . . . . . . . . # # # # . . . . # # # . . . . . . . \n",
      ". . . . . . . . . . # # # . . . . # # # . . . . . . . . \n",
      ". . . . . . . . . . # # # . . . # # # . . . . . . . . . \n",
      ". . . . . . . . . . # # # # . # # # . . . . . . . . . . \n",
      ". . . . . . . . . . . # # # # # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . . # # # # . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . # # # # . . . . . . . . . . . . \n",
      ". . . . . . . . . . . # # # # # . . . . . . . . . . . . \n",
      ". . . . . . . . . . # # # # # # . . . . . . . . . . . . \n",
      ". . . . . . . . . # # # . . # # . . . . . . . . . . . . \n",
      ". . . . . . . . # # # . . . # # . . . . . . . . . . . . \n",
      ". . . . . . . . # # . . . # # # . . . . . . . . . . . . \n",
      ". . . . . . . . # # . . # # # # . . . . . . . . . . . . \n",
      ". . . . . . . . # # # # # # # . . . . . . . . . . . . . \n",
      ". . . . . . . . # # # # # # . . . . . . . . . . . . . . \n",
      ". . . . . . . . . # # # . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Label:  8\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . # # . . . . . . . . . . . \n",
      ". . . . . . . . . # # # # # # # # # # # . . . . . . . . \n",
      ". . . . . . . . # # # # # # # # # . # . . . . . . . . . \n",
      ". . . . . . . . # # # # . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . # # # . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . # # # # . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . # # # # . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . # # # # # # . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . # # # # # # # # # # # # # . . . . \n",
      ". . . . . . . # # # . . # # # # # # # # # # # # # . . . \n",
      ". . . . . . . # # # . . . . . . . . . . . . # # # # . . \n",
      ". . . . . . # # # # . . . . . . . . . . . . # # # . . . \n",
      ". . . . . . # # # # . . . . . . . . . . . # # # # . . . \n",
      ". . . . . . # # # # . . . . . . . . . . # # # # . . . . \n",
      ". . . . . . # # # # . . . . . . . . . # # # # . . . . . \n",
      ". . . . . . # # # # . . . . . . . # # # # # . . . . . . \n",
      ". . . . . . # # # # . . . . . # # # # # # . . . . . . . \n",
      ". . . . . . # # # # # . # # # # # # # # . . . . . . . . \n",
      ". . . . . . . # # # # # # # # # # . . . . . . . . . . . \n",
      ". . . . . . . . . # # # # # # . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Label:  5\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . # # . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . # . . . . . . . . \n",
      ". . . . . . . . . # . . . . . . . . # # . . . . . . . . \n",
      ". . . . . . . . # # . . . . . . . . # # . . . . . . . . \n",
      ". . . . . . . . # # . . . . . . . # # # . . . . . . . . \n",
      ". . . . . . . . # # . . . . . . . # # . . . . . . . . . \n",
      ". . . . . . . # # . . . . . . . # # . . . . . . . . . . \n",
      ". . . . . . . # # . . . . . . . # # . . . . . . . . . . \n",
      ". . . . . . . # # . . . . . . . # # . . . . . . . . . . \n",
      ". . . . . . . # # . . . . # # # # # # # # . . . . . . . \n",
      ". . . . . . . # # # # # # # # # # # . . . . . . . . . . \n",
      ". . . . . . . . . . # # . . . # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . # # . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . # # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . # # . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Label:  4\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . # . . . # . . . . . . . . . \n",
      ". . . . . . . . . . . . . # # . . . # # . . . . . . . . \n",
      ". . . . . . . . . . . . . # # . . . # # . . . . . . . . \n",
      ". . . . . . . . . . . # # # . . . . # # . . . . . . . . \n",
      ". . . . . . . . . . # # # # . . . . # # . . . . . . . . \n",
      ". . . . . . . . . . # # # . . . . . # # . . . . . . . . \n",
      ". . . . . . . . . . # # # . . . . . # # . . . . . . . . \n",
      ". . . . . . . . . # # # # . . . . . # # . . . . . . . . \n",
      ". . . . . . . . # # # # . . . . . . # # . . . . . . . . \n",
      ". . . . . . . . # # # # . . . . . # # # . . . . . . . . \n",
      ". . . . . . . # # # # # # # # # # # # . . . . . . . . . \n",
      ". . . . . . # # # # # # # # # # # # # . . . . . . . . . \n",
      ". . . . . . . # # # # # # # # # # # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . # # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . # # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . # # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Label:  4\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . # # # # # . . # . . . . . . . . . . . \n",
      ". . . . . . . . . # # # # # # # # # # # # # . . . . . . \n",
      ". . . . . . . . . # . . . . # # # # # # # # . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . # # # # . . . . . . \n",
      ". . . . . . . . . . . . . . . . # # # # # . . . . . . . \n",
      ". . . . . . . . . . . . . . # # # # # # . . . . . . . . \n",
      ". . . . . . . . . . . . # # # # # # . . . . . . . . . . \n",
      ". . . . . . . . . . # # # # # . . . . . . . . . . . . . \n",
      ". . . . . . . . . # # # # # # . . . . . . . . . . . . . \n",
      ". . . . . . . . . . # # # # # # # # . . . . . . . . . . \n",
      ". . . . . . . . . . . . . # # # # # # # . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . # # # # . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . # # # . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . # # . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . # # # . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . # # # # . . . . . . . . \n",
      ". . . . . . # # . . . . . . . # # # # . . . . . . . . . \n",
      ". . . . . # # # . . . . # # # # # # . . . . . . . . . . \n",
      ". . . . . # # # # # # # # # # # . . . . . . . . . . . . \n",
      ". . . . . . . # # # # # # # . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Label:  3\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . # # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . # # # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . # # # # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . # # # # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . # # # # # # . . . . . . . . . \n",
      ". . . . . . . . . . . . # # # . # # . . . . . . . . . . \n",
      ". . . . . . . . . . . . # # . . # # . . . . . . . . . . \n",
      ". . . . . . . . . . . # # . . # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . # . . # # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . # # . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . # # # . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . # # . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . # # # . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . # # . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . # # . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . # # # . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . # # . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . # # . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . # # . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . # . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Label:  1\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . # # # # # # . . . . . . . . . . . . . \n",
      ". . . . . . . . # # # # # # # # # . . . . . . . . . . . \n",
      ". . . . . . . . # # . . . . . . # # # . . . . . . . . . \n",
      ". . . . . . . . # # . . . . . . . # # . . . . . . . . . \n",
      ". . . . . . . . # # # . . . . . . # # . . . . . . . . . \n",
      ". . . . . . . . . # # # . . . . . # . . . . . . . . . . \n",
      ". . . . . . . . . . # # # . . . # # # # # . . . . . . . \n",
      ". . . . . . . . . . . # # # . # # # . . . . . . . . . . \n",
      ". . . . . . . . . . . . # # # # . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . # # # # . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . # # # # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . # # . . # # # . . . . . . . . . . \n",
      ". . . . . . . . . . . # # . . . # # # . . . . . . . . . \n",
      ". . . . . . . . . . . # . . . . . # # . . . . . . . . . \n",
      ". . . . . . . . . . # # . . . . . # # # . . . . . . . . \n",
      ". . . . . . . . . . # # . . . . . . # # # . . . . . . . \n",
      ". . . . . . . . . . . # # . . . . . . # # . . . . . . . \n",
      ". . . . . . . . . . . # # # # . . . # # # . . . . . . . \n",
      ". . . . . . . . . . . . # # # # # # # # . . . . . . . . \n",
      ". . . . . . . . . . . . . # # # # # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Label:  8\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . # # # . . . . . . . . . . . \n",
      ". . . . . . . . . # # . # # # # # # # . . . . . . . . . \n",
      ". . . . . . . . # # # # # # . . . # # . . . . . . . . . \n",
      ". . . . . . . # # . . # # . . . . . # # . . . . . . . . \n",
      ". . . . . . . # # . . . # . . . . . # # . . . . . . . . \n",
      ". . . . . . . # # # . . . . . . . . # # . . . . . . . . \n",
      ". . . . . . . . # # # . . . . . . . # # . . . . . . . . \n",
      ". . . . . . . . . # # # . . . . # # # . . . . . . . . . \n",
      ". . . . . . . . . . # # # # # # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . # # # # # . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . # # # # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . # # . . # # # . . . . . . . . . . \n",
      ". . . . . . . . . . . # # . . . # # . . . . . . . . . . \n",
      ". . . . . . . . . . # # # . . . . # # . . . . . . . . . \n",
      ". . . . . . . . . . # # # . . . . # # . . . . . . . . . \n",
      ". . . . . . . . . . # # # . . . . # # . . . . . . . . . \n",
      ". . . . . . . . . . . # # . . . . # # . . . . . . . . . \n",
      ". . . . . . . . . . . # # # . . # # # . . . . . . . . . \n",
      ". . . . . . . . . . . . # # # # # # . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . # # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Label:  8\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . # # # # . . . . . . . . . \n",
      ". . . . . . . . . . . . . # # # # # # # . . . . . . . . \n",
      ". . . . . . . . . . . . # # # # # # # # . . . . . . . . \n",
      ". . . . . . . . . . . # # # # . . . . # . . . . . . . . \n",
      ". . . . . . . . . . # # # . . . . . # . . . . . . . . . \n",
      ". . . . . . . . . # # # . . . . . # # . . . . . . . . . \n",
      ". . . . . . . . . # # # . . . # # # # . . . . . . . . . \n",
      ". . . . . . . . # # # . # # # # # # . . . . . . . . . . \n",
      ". . . . . . . . # # # # # # # # # # . . . . . . . . . . \n",
      ". . . . . . . . . # # # # # # # # # . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . # # # . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . # # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . # # # . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . # # . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . # # . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . # # # . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . # # # # . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . # # # . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . # # # . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . # # . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Label:  9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print_digit(trainX[i], trainY[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import sys\n",
    "\n",
    "\n",
    "class NeuralNetMLP(object):\n",
    "    \"\"\" Feedforward neural network / Multi-layer perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    n_output : int\n",
    "      Number of output units, should be equal to the\n",
    "      number of unique class labels.\n",
    "\n",
    "    n_features : int\n",
    "      Number of features (dimensions) in the target dataset.\n",
    "      Should be equal to the number of columns in the X array.\n",
    "\n",
    "    n_hidden : int (default: 30)\n",
    "      Number of hidden units.\n",
    "\n",
    "    l1 : float (default: 0.0)\n",
    "      Lambda value for L1-regularization.\n",
    "      No regularization if l1=0.0 (default)\n",
    "\n",
    "    l2 : float (default: 0.0)\n",
    "      Lambda value for L2-regularization.\n",
    "      No regularization if l2=0.0 (default)\n",
    "\n",
    "    epochs : int (default: 500)\n",
    "      Number of passes over the training set.\n",
    "\n",
    "    eta : float (default: 0.001)\n",
    "      Learning rate.\n",
    "\n",
    "    alpha : float (default: 0.0)\n",
    "      Momentum constant. Factor multiplied with the\n",
    "      gradient of the previous epoch t-1 to improve\n",
    "      learning speed\n",
    "      w(t) := w(t) - (grad(t) + alpha*grad(t-1))\n",
    "    \n",
    "    decrease_const : float (default: 0.0)\n",
    "      Decrease constant. Shrinks the learning rate\n",
    "      after each epoch via eta / (1 + epoch*decrease_const)\n",
    "\n",
    "    shuffle : bool (default: True)\n",
    "      Shuffles training data every epoch if True to prevent circles.\n",
    "\n",
    "    minibatches : int (default: 1)\n",
    "      Divides training data into k minibatches for efficiency.\n",
    "      Normal gradient descent learning if k=1 (default).\n",
    "\n",
    "    random_state : int (default: None)\n",
    "      Set random state for shuffling and initializing the weights.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    cost_ : list\n",
    "      Sum of squared errors after each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_output, n_features, n_hidden=30,\n",
    "                 l1=0.0, l2=0.0, epochs=500, eta=0.001, \n",
    "                 alpha=0.0, decrease_const=0.0, shuffle=True, \n",
    "                 minibatches=1, random_state=None):\n",
    "\n",
    "        np.random.seed(random_state)\n",
    "        self.n_output = n_output\n",
    "        self.n_features = n_features\n",
    "        self.n_hidden = n_hidden\n",
    "        self.w1, self.w2 = self._initialize_weights()\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.alpha = alpha\n",
    "        self.decrease_const = decrease_const\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatches = minibatches\n",
    "\n",
    "    def _encode_labels(self, y, k):\n",
    "        \"\"\"Encode labels into one-hot representation\n",
    "\n",
    "        Parameters\n",
    "        ------------\n",
    "        y : array, shape = [n_samples]\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        onehot : array, shape = (n_labels, n_samples)\n",
    "\n",
    "        \"\"\"\n",
    "        onehot = np.zeros((k, y.shape[0]))\n",
    "        for idx, val in enumerate(y):\n",
    "            onehot[val, idx] = 1.0\n",
    "        return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        w1 = np.random.uniform(-1.0, 1.0, size=self.n_hidden*(self.n_features + 1))\n",
    "        w1 = w1.reshape(self.n_hidden, self.n_features + 1)\n",
    "        w2 = np.random.uniform(-1.0, 1.0, size=self.n_output*(self.n_hidden + 1))\n",
    "        w2 = w2.reshape(self.n_output, self.n_hidden + 1)\n",
    "        return w1, w2\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        \"\"\"Compute logistic function (sigmoid)\n",
    "\n",
    "        Uses scipy.special.expit to avoid overflow\n",
    "        error for very small input values z.\n",
    "\n",
    "        \"\"\"\n",
    "        # return 1.0 / (1.0 + np.exp(-z))\n",
    "        return expit(z)\n",
    "\n",
    "    def _sigmoid_gradient(self, z):\n",
    "        \"\"\"Compute gradient of the logistic function\"\"\"\n",
    "        sg = self._sigmoid(z)\n",
    "        return sg * (1 - sg)\n",
    "\n",
    "    def _add_bias_unit(self, X, how='column'):\n",
    "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
    "        if how == 'column':\n",
    "            X_new = np.ones((X.shape[0], X.shape[1]+1))\n",
    "            X_new[:, 1:] = X\n",
    "        elif how == 'row':\n",
    "            X_new = np.ones((X.shape[0]+1, X.shape[1]))\n",
    "            X_new[1:, :] = X\n",
    "        else:\n",
    "            raise AttributeError('`how` must be `column` or `row`')\n",
    "        return X_new\n",
    "\n",
    "    def _feedforward(self, X, w1, w2):\n",
    "        \"\"\"Compute feedforward step\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : array, shape = [n_samples, n_features]\n",
    "          Input layer with original features.\n",
    "\n",
    "        w1 : array, shape = [n_hidden_units, n_features]\n",
    "          Weight matrix for input layer -> hidden layer.\n",
    "\n",
    "        w2 : array, shape = [n_output_units, n_hidden_units]\n",
    "          Weight matrix for hidden layer -> output layer.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        a1 : array, shape = [n_samples, n_features+1]\n",
    "          Input values with bias unit.\n",
    "\n",
    "        z2 : array, shape = [n_hidden, n_samples]\n",
    "          Net input of hidden layer.\n",
    "\n",
    "        a2 : array, shape = [n_hidden+1, n_samples]\n",
    "          Activation of hidden layer.\n",
    "\n",
    "        z3 : array, shape = [n_output_units, n_samples]\n",
    "          Net input of output layer.\n",
    "\n",
    "        a3 : array, shape = [n_output_units, n_samples]\n",
    "          Activation of output layer.\n",
    "\n",
    "        \"\"\"\n",
    "        a1 = self._add_bias_unit(X, how='column')\n",
    "        z2 = w1.dot(a1.T)\n",
    "        a2 = self._sigmoid(z2)\n",
    "        a2 = self._add_bias_unit(a2, how='row')\n",
    "        z3 = w2.dot(a2)\n",
    "        a3 = self._sigmoid(z3)\n",
    "        return a1, z2, a2, z3, a3\n",
    "\n",
    "    def _L2_reg(self, lambda_, w1, w2):\n",
    "        \"\"\"Compute L2-regularization cost\"\"\"\n",
    "        return (lambda_/2.0) * (np.sum(w1[:, 1:] ** 2) + np.sum(w2[:, 1:] ** 2))\n",
    "\n",
    "    def _L1_reg(self, lambda_, w1, w2):\n",
    "        \"\"\"Compute L1-regularization cost\"\"\"\n",
    "        return (lambda_/2.0) * (np.abs(w1[:, 1:]).sum() + np.abs(w2[:, 1:]).sum())\n",
    "\n",
    "    def _get_cost(self, y_enc, output, w1, w2):\n",
    "        \"\"\"Compute cost function.\n",
    "\n",
    "        y_enc : array, shape = (n_labels, n_samples)\n",
    "          one-hot encoded class labels.\n",
    "\n",
    "        output : array, shape = [n_output_units, n_samples]\n",
    "          Activation of the output layer (feedforward)\n",
    "\n",
    "        w1 : array, shape = [n_hidden_units, n_features]\n",
    "          Weight matrix for input layer -> hidden layer.\n",
    "\n",
    "        w2 : array, shape = [n_output_units, n_hidden_units]\n",
    "          Weight matrix for hidden layer -> output layer.\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        cost : float\n",
    "          Regularized cost.\n",
    "\n",
    "        \"\"\"\n",
    "        term1 = -y_enc * (np.log(output))\n",
    "        term2 = (1 - y_enc) * np.log(1 - output)\n",
    "        cost = np.sum(term1 - term2)\n",
    "        L1_term = self._L1_reg(self.l1, w1, w2)\n",
    "        L2_term = self._L2_reg(self.l2, w1, w2)\n",
    "        cost = cost + L1_term + L2_term\n",
    "        return cost\n",
    "\n",
    "    def _get_gradient(self, a1, a2, a3, z2, y_enc, w1, w2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "\n",
    "        Parameters\n",
    "        ------------\n",
    "        a1 : array, shape = [n_samples, n_features+1]\n",
    "          Input values with bias unit.\n",
    "\n",
    "        a2 : array, shape = [n_hidden+1, n_samples]\n",
    "          Activation of hidden layer.\n",
    "\n",
    "        a3 : array, shape = [n_output_units, n_samples]\n",
    "          Activation of output layer.\n",
    "\n",
    "        z2 : array, shape = [n_hidden, n_samples]\n",
    "          Net input of hidden layer.\n",
    "\n",
    "        y_enc : array, shape = (n_labels, n_samples)\n",
    "          one-hot encoded class labels.\n",
    "\n",
    "        w1 : array, shape = [n_hidden_units, n_features]\n",
    "          Weight matrix for input layer -> hidden layer.\n",
    "\n",
    "        w2 : array, shape = [n_output_units, n_hidden_units]\n",
    "          Weight matrix for hidden layer -> output layer.\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "\n",
    "        grad1 : array, shape = [n_hidden_units, n_features]\n",
    "          Gradient of the weight matrix w1.\n",
    "\n",
    "        grad2 : array, shape = [n_output_units, n_hidden_units]\n",
    "            Gradient of the weight matrix w2.\n",
    "\n",
    "        \"\"\"\n",
    "        # backpropagation\n",
    "        sigma3 = a3 - y_enc\n",
    "        z2 = self._add_bias_unit(z2, how='row')\n",
    "        sigma2 = w2.T.dot(sigma3) * self._sigmoid_gradient(z2)\n",
    "        sigma2 = sigma2[1:, :]\n",
    "        grad1 = sigma2.dot(a1)\n",
    "        grad2 = sigma3.dot(a2.T)\n",
    "\n",
    "        # regularize\n",
    "        grad1[:, 1:] += (w1[:, 1:] * (self.l1 + self.l2))\n",
    "        grad2[:, 1:] += (w2[:, 1:] * (self.l1 + self.l2))\n",
    "\n",
    "        return grad1, grad2\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : array, shape = [n_samples, n_features]\n",
    "          Input layer with original features.\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        y_pred : array, shape = [n_samples]\n",
    "          Predicted class labels.\n",
    "\n",
    "        \"\"\"\n",
    "        if len(X.shape) != 2:\n",
    "            raise AttributeError('X must be a [n_samples, n_features] array.\\n'\n",
    "                                 'Use X[:,None] for 1-feature classification,'\n",
    "                                 '\\nor X[[i]] for 1-sample classification')\n",
    "\n",
    "        a1, z2, a2, z3, a3 = self._feedforward(X, self.w1, self.w2)\n",
    "        y_pred = np.argmax(z3, axis=0)\n",
    "        return y_pred\n",
    "\n",
    "    def fit(self, X, y, print_progress=False):\n",
    "        \"\"\" Learn weights from training data.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X : array, shape = [n_samples, n_features]\n",
    "          Input layer with original features.\n",
    "\n",
    "        y : array, shape = [n_samples]\n",
    "          Target class labels.\n",
    "\n",
    "        print_progress : bool (default: False)\n",
    "          Prints progress as the number of epochs\n",
    "          to stderr.\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        self\n",
    "\n",
    "        \"\"\"\n",
    "        self.cost_ = []\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        y_enc = self._encode_labels(y, self.n_output)\n",
    "\n",
    "        delta_w1_prev = np.zeros(self.w1.shape)\n",
    "        delta_w2_prev = np.zeros(self.w2.shape)\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            # adaptive learning rate\n",
    "            self.eta /= (1 + self.decrease_const*i)\n",
    "\n",
    "            if print_progress:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx = np.random.permutation(y_data.shape[0])\n",
    "                X_data, y_enc = X_data[idx], y_enc[:, idx]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            for idx in mini:\n",
    "\n",
    "                # feedforward\n",
    "                a1, z2, a2, z3, a3 = self._feedforward(X_data[idx], self.w1, self.w2)\n",
    "                cost = self._get_cost(y_enc=y_enc[:, idx],\n",
    "                                      output=a3,\n",
    "                                      w1=self.w1,\n",
    "                                      w2=self.w2)\n",
    "                self.cost_.append(cost)\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                grad1, grad2 = self._get_gradient(a1=a1, a2=a2,\n",
    "                                                  a3=a3, z2=z2,\n",
    "                                                  y_enc=y_enc[:, idx],\n",
    "                                                  w1=self.w1,\n",
    "                                                  w2=self.w2)\n",
    "\n",
    "                delta_w1, delta_w2 = self.eta * grad1, self.eta * grad2\n",
    "                self.w1 -= (delta_w1 + (self.alpha * delta_w1_prev))\n",
    "                self.w2 -= (delta_w2 + (self.alpha * delta_w2_prev))\n",
    "                delta_w1_prev, delta_w2_prev = delta_w1, delta_w2\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetMLP(n_output=10, \n",
    "                  n_features=trainX.shape[1], #not considering shape[2]\n",
    "                  n_hidden=50, \n",
    "                  l2=0.1, \n",
    "                  l1=0.0, \n",
    "                  epochs=1000, \n",
    "                  eta=0.001,\n",
    "                  alpha=0.001,\n",
    "                  decrease_const=0.00001,\n",
    "                  minibatches=50, \n",
    "                  shuffle=True,\n",
    "                  random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
